{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intro\n",
    "This notebook is an analysis of a web archive file.  Most of it was authored by ChatGPT - it's a great example of using ChatGPT to jump-start analysis or development.\n",
    "\n",
    "In this first cell, I'd asket ChatGPT to analyze the page load requests of a web site and summarize calls to third-party web sites.  It asked me to upload a HAR file and then it gave these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'domain': 'ir.ebaystatic.com', 'requests': 28},\n",
       " {'domain': 'i.ebayimg.com', 'requests': 92},\n",
       " {'domain': 'secureir.ebaystatic.com', 'requests': 1},\n",
       " {'domain': 'srv.main.ebayrtm.com', 'requests': 2},\n",
       " {'domain': 'www.ebayadservices.com', 'requests': 1},\n",
       " {'domain': 's3.amazonaws.com', 'requests': 1},\n",
       " {'domain': 'dynamic.criteo.com', 'requests': 1},\n",
       " {'domain': 'sp.analytics.yahoo.com', 'requests': 1},\n",
       " {'domain': 's.pinimg.com', 'requests': 2},\n",
       " {'domain': 'connect.facebook.net', 'requests': 1}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the HAR file to analyze it\n",
    "har_file_path = './ebay.har'\n",
    "\n",
    "with open(har_file_path, 'r') as file:\n",
    "    har_data = json.load(file)\n",
    "\n",
    "# Extract the requests from the HAR file\n",
    "requests = []\n",
    "for entry in har_data.get('log', {}).get('entries', []):\n",
    "    request = entry.get('request', {})\n",
    "    if request:\n",
    "        url = request.get('url', '')\n",
    "        domain = url.split('/')[2] if '://' in url else url\n",
    "        requests.append(domain)\n",
    "\n",
    "# Count occurrences of each domain\n",
    "from collections import Counter\n",
    "\n",
    "domain_counts = Counter(requests)\n",
    "\n",
    "# Identify third-party domains\n",
    "primary_domain = 'ebay.com'\n",
    "third_party_domains = {domain: count for domain, count in domain_counts.items() if primary_domain not in domain}\n",
    "\n",
    "# Summarize third-party domains\n",
    "third_party_summary = [{\"domain\": domain, \"requests\": count} for domain, count in third_party_domains.items()]\n",
    "third_party_summary[:10]  # Show the top 10 for an initial check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning a bit, I asked ChatGPT to include the likely purpose of each domain connection.  Note the array of domain purposes in the cell below - it's likely you'd need to augment and/or tweak these a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'tld': 'ebayimg.com', 'requests': 92, 'purpose': 'Unknown'},\n",
       "  {'tld': 'ebaystatic.com', 'requests': 29, 'purpose': 'Unknown'},\n",
       "  {'tld': 'doubleclick.net', 'requests': 10, 'purpose': 'Unknown'},\n",
       "  {'tld': 'criteo.com', 'requests': 6, 'purpose': 'Unknown'},\n",
       "  {'tld': 'pinterest.com', 'requests': 6, 'purpose': 'Unknown'},\n",
       "  {'tld': 'google.com',\n",
       "   'requests': 5,\n",
       "   'purpose': 'Various services, e.g., reCAPTCHA, APIs'},\n",
       "  {'tld': 'snapchat.com', 'requests': 5, 'purpose': 'Unknown'},\n",
       "  {'tld': 'googletagmanager.com',\n",
       "   'requests': 3,\n",
       "   'purpose': 'Tag management for marketing and analytics'},\n",
       "  {'tld': 'amplitude.com', 'requests': 3, 'purpose': 'Unknown'},\n",
       "  {'tld': 'ebayrtm.com', 'requests': 2, 'purpose': 'Unknown'}],\n",
       " './tld_summary.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarize third-party requests by top-level domain (TLD)\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Extract top-level domains and summarize with purposes\n",
    "domain_purposes = {\n",
    "    \"google-analytics.com\": \"Website traffic tracking and analytics\",\n",
    "    \"googletagmanager.com\": \"Tag management for marketing and analytics\",\n",
    "    \"google.com\": \"Various services, e.g., reCAPTCHA, APIs\",\n",
    "    \"bing.com\": \"Microsoft Bing Ads tracking and analytics\",\n",
    "    \"facebook.net\": \"Facebook plugins and ad tracking\",\n",
    "    \"facebook.com\": \"Facebook tracking pixels and widgets\",\n",
    "    \"criteo.net\": \"Personalized retargeting ads\",\n",
    "}\n",
    "\n",
    "# Summarize requests by top-level domain and annotate purposes\n",
    "tld_summary = {}\n",
    "for domain, count in third_party_domains.items():\n",
    "    tld = \".\".join(domain.split(\".\")[-2:])  # Extract TLD (e.g., \"google.com\")\n",
    "    if tld not in tld_summary:\n",
    "        tld_summary[tld] = {\"requests\": 0, \"purpose\": domain_purposes.get(tld, \"Unknown\")}\n",
    "    tld_summary[tld][\"requests\"] += count\n",
    "\n",
    "# Convert summary to a sorted list\n",
    "tld_summary_list = [\n",
    "    {\"tld\": tld, \"requests\": data[\"requests\"], \"purpose\": data[\"purpose\"]}\n",
    "    for tld, data in tld_summary.items()\n",
    "]\n",
    "tld_summary_sorted = sorted(tld_summary_list, key=lambda x: x[\"requests\"], reverse=True)\n",
    "\n",
    "# Save the TLD summary as a JSON file for user download\n",
    "tld_summary_file_path = './tld_summary.json'\n",
    "with open(tld_summary_file_path, 'w') as output_file:\n",
    "    json.dump(tld_summary_sorted, output_file, indent=2)\n",
    "\n",
    "tld_summary_sorted[:10], tld_summary_file_path  # Preview the top 10 and provide file path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last cell, I asked to categorize small gif files as \"tracking\" in addition to the known domains identified earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'tld': 'ebayimg.com', 'requests': 92, 'purpose': 'Unknown'},\n",
       "  {'tld': 'ebaystatic.com', 'requests': 29, 'purpose': 'Unknown'},\n",
       "  {'tld': 'doubleclick.net', 'requests': 10, 'purpose': 'Unknown'},\n",
       "  {'tld': 'criteo.com', 'requests': 6, 'purpose': 'Unknown'},\n",
       "  {'tld': 'pinterest.com', 'requests': 6, 'purpose': 'Unknown'},\n",
       "  {'tld': 'google.com',\n",
       "   'requests': 5,\n",
       "   'purpose': 'Various services, e.g., reCAPTCHA, APIs'},\n",
       "  {'tld': 'snapchat.com', 'requests': 5, 'purpose': 'Unknown'},\n",
       "  {'tld': 'googletagmanager.com',\n",
       "   'requests': 3,\n",
       "   'purpose': 'Tag management for marketing and analytics'},\n",
       "  {'tld': 'amplitude.com', 'requests': 3, 'purpose': 'Unknown'},\n",
       "  {'tld': 'ebayrtm.com', 'requests': 2, 'purpose': 'Unknown'}],\n",
       " './updated_tld_summary.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-examine requests to identify if \"unknown\" domains are used for tracking (e.g., small GIF files)\n",
    "\n",
    "# Collect request sizes and purposes\n",
    "domain_request_details = {}\n",
    "for entry in har_data.get('log', {}).get('entries', []):\n",
    "    request = entry.get('request', {})\n",
    "    response = entry.get('response', {})\n",
    "    if request and response:\n",
    "        url = request.get('url', '')\n",
    "        domain = url.split('/')[2] if '://' in url else url\n",
    "        size = response.get('content', {}).get('size', 0)\n",
    "        if domain not in domain_request_details:\n",
    "            domain_request_details[domain] = {\"total_requests\": 0, \"gif_requests\": 0}\n",
    "        domain_request_details[domain][\"total_requests\"] += 1\n",
    "        if url.endswith(\".gif\") and size < 1000:  # Small GIF threshold\n",
    "            domain_request_details[domain][\"gif_requests\"] += 1\n",
    "\n",
    "# Update purposes for domains with unknown purposes\n",
    "for tld in tld_summary:\n",
    "    if tld_summary[tld][\"purpose\"] == \"Unknown\":\n",
    "        gif_requests = sum(\n",
    "            details[\"gif_requests\"]\n",
    "            for domain, details in domain_request_details.items()\n",
    "            if domain.endswith(tld)\n",
    "        )\n",
    "        total_requests = tld_summary[tld][\"requests\"]\n",
    "        if gif_requests == total_requests:\n",
    "            tld_summary[tld][\"purpose\"] = \"Tracking\"\n",
    "\n",
    "# Convert the updated TLD summary to a sorted list\n",
    "updated_tld_summary_list = [\n",
    "    {\"tld\": tld, \"requests\": data[\"requests\"], \"purpose\": data[\"purpose\"]}\n",
    "    for tld, data in tld_summary.items()\n",
    "]\n",
    "updated_tld_summary_sorted = sorted(\n",
    "    updated_tld_summary_list, key=lambda x: x[\"requests\"], reverse=True\n",
    ")\n",
    "\n",
    "# Save the updated TLD summary as a JSON file for user download\n",
    "updated_tld_summary_file_path = './updated_tld_summary.json'\n",
    "with open(updated_tld_summary_file_path, 'w') as output_file:\n",
    "    json.dump(updated_tld_summary_sorted, output_file, indent=2)\n",
    "\n",
    "updated_tld_summary_sorted[:10], updated_tld_summary_file_path  # Preview top 10 and file path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
